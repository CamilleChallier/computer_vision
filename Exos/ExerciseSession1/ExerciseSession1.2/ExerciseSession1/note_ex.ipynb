{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toujours verif si grayscale et si float (np.float32(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: OpenCV reads color images in order of BGR (blue, green, red channels) but pyplot visualizes them as RGB. apple = apple[:, :, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.cvtColor() :\n",
    "    \n",
    "# src: Input image (NumPy array).\n",
    "\n",
    "# code: Color space conversion code. It specifies the type of color space conversion to be performed. This is an integer value representing the color space conversion, e.g., cv2.COLOR_BGR2GRAY, cv2.COLOR_BGR2HSV, etc.\n",
    "\n",
    "# dst (optional): Output image (NumPy array) having the same size and depth as the input src. It stores the result of the color space conversion.\n",
    "\n",
    "# dstCn (optional): The number of channels in the destination image. If dstCn is 0, the number of channels is derived automatically from code.\n",
    "    \n",
    "# exemple : img_shading = cv2.cvtColor(img_shading, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imread(filename, flag) \n",
    "\n",
    "# Parameters:\n",
    "\n",
    "# filename: The path to the image file.\n",
    "# flag: The flag specifies the way how the image should be read.\n",
    "# cv2.IMREAD_COLOR – It specifies to load a color image. Any transparency of image will be neglected. It is the default flag. Alternatively, we can pass integer value 1 for this flag.\n",
    "# cv2.IMREAD_GRAYSCALE – It specifies to load an image in grayscale mode. Alternatively, we can pass integer value 0 for this flag. \n",
    "# cv2.IMREAD_UNCHANGED – It specifies to load an image as such including alpha channel. Alternatively, we can pass integer value -1 for this flag.\n",
    "\n",
    "# exemple : image_1 = cv2.imread('images/street1.tiff',cv2.IMREAD_GRAYSCALE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o : black, 255 : white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax: cv2.split(m[, mv])\n",
    "\n",
    "# Parameters:\n",
    "\n",
    "# m: Input multi-channel array\n",
    "# mv: Output vector of arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax: cv2.merge(mv[, dst])\n",
    "\n",
    "# Parameters:\n",
    "\n",
    "# mv: Input vector of matrices to be merged. All matrices must have same size.\n",
    "# dst: Output multi-channel array of size mv[0]. Number of channel will be equal to total no. of channel in matrix array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dst = cv2.GaussianBlur(src, ksize, sigmaX[, dst[, sigmaY[, borderType=BORDER_DEFAULT]]] )\n",
    "# Parameter\tDescription\n",
    "# src\tinput image\n",
    "# dst\toutput image\n",
    "# ksize\tGaussian Kernel Size. [height width]. height and width should be odd and can have different values. If ksize is set to [0 0], then ksize is computed from sigma values.\n",
    "# sigmaX\tKernel standard deviation along X-axis (horizontal direction).\n",
    "# sigmaY\tKernel standard deviation along Y-axis (vertical direction). If sigmaY=0, then sigmaX value is taken for sigmaY\n",
    "# borderType\tSpecifies image boundaries while kernel is applied on image borders. Possible values are : cv.BORDER_CONSTANT cv.BORDER_REPLICATE cv.BORDER_REFLECT cv.BORDER_WRAP cv.BORDER_REFLECT_101 cv.BORDER_TRANSPARENT cv.BORDER_REFLECT101 cv.BORDER_DEFAULT cv.BORDER_ISOLATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobel(src, dst, ddepth, dx, dy)\n",
    "# This method accepts the following parameters −\n",
    "\n",
    "# src − An object of the class Mat representing the source (input) image.\n",
    "\n",
    "# dst − An object of the class Mat representing the destination (output) image.\n",
    "\n",
    "# ddepth − An integer variable representing the depth of the image (-1), cv2.CV_64F\n",
    "\n",
    "# dx − An integer variable representing the x-derivative. (0 or 1)\n",
    "\n",
    "# dy − An integer variable representing the y-derivative. (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(wdg.ravel(), 256, [0,256])\n",
    "# data, bins number, range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subplots\n",
    "\n",
    "# fig, axs = plt.subplots(2, 2)\n",
    "# axs[0, 0].plot(x, y)\n",
    "# axs[0, 0].set_title(\"main\")\n",
    "# axs[1, 0].plot(x, y**2)\n",
    "# axs[1, 0].set_title(\"shares x with main\")\n",
    "# axs[1, 0].sharex(axs[0, 0])\n",
    "# axs[0, 1].plot(x + 1, y + 1)\n",
    "# axs[0, 1].set_title(\"unrelated\")\n",
    "# axs[1, 1].plot(x + 2, y + 2)\n",
    "# axs[1, 1].set_title(\"also unrelated\")\n",
    "# for ax in axs.flat:\n",
    "#     ax.set(xlabel='x-label', ylabel='y-label')\n",
    "# fig.tight_layout()\n",
    "\n",
    "# fig, (ax1, ax2) = plt.subplots(1,2, sharex=True)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# plt.subplot(1,2,1)\n",
    "# grady = plt.imshow(grad_x,cmap=\"jet\")\n",
    "# plt.title(\"Gradient x\")\n",
    "# plt.colorbar(fraction=0.046, pad=0.04)\n",
    "# plt.subplot(1,2,2)\n",
    "# gradx = plt.imshow(grad_y,cmap=\"jet\")\n",
    "# plt.title(\"Gradient y\")\n",
    "# plt.colorbar(fraction=0.046, pad=0.04)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax = plt.axes(projection='3d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # skimage.measure.label(label_image, background=None, return_num=False, connectivity=None)[source]\n",
    "\n",
    "# Two pixels are connected when they are neighbors and have the same value. In 2D, they can be neighbors either in a 1- or 2-connected sense. The value refers to the maximum number of orthogonal hops to consider a pixel/voxel a neighbor:\n",
    "\n",
    "# Parameters\n",
    "# :\n",
    "# label_image\n",
    "# ndarray of dtype int\n",
    "# Image to label.\n",
    "\n",
    "# background\n",
    "# int, optional\n",
    "# Consider all pixels with this value as background pixels, and label them as 0. By default, 0-valued pixels are considered as background pixels.\n",
    "\n",
    "# return_num\n",
    "# bool, optional\n",
    "# Whether to return the number of assigned labels.\n",
    "\n",
    "# connectivity\n",
    "# int, optional\n",
    "# Maximum number of orthogonal hops to consider a pixel/voxel as a neighbor. Accepted values are ranging from 1 to input.ndim. If None, a full connectivity of input.ndim is used.\n",
    "\n",
    "# Returns\n",
    "# :\n",
    "# labels\n",
    "# ndarray of dtype int\n",
    "# Labeled array, where all connected regions are assigned the same integer value.\n",
    "\n",
    "# num\n",
    "# int, optional\n",
    "# Number of labels, which equals the maximum label index and is only returned if return_num is True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.signal as conv\n",
    "# output_2 = conv.convolve2d(img, F , mode='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_of_images = listdir('images/sequence1/')  \n",
    "sq_of_images = [img for img in sq_of_images if img.endswith(\".jpg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in [(x,y) for x in range(len(sizes)) for y in range(len(sigmas))]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "_2D_filter_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coord_grid(min_val=0, max_val=1, num_x=100, num_y=100):\n",
    "    '''\n",
    "    inputs:\n",
    "        min_val, max_val (float): minimum and maximum values in the grid range\n",
    "        num_x, num_y (int): number of points to sample\n",
    "    outputs:\n",
    "        coord_grid (np.array): (num_x*num_y x 2) - the grid of input 2D coordinates, reshaped in the array of points\n",
    "    '''\n",
    "    assert min_val < max_val\n",
    "    \n",
    "    coord_grid = np.meshgrid(\n",
    "        np.linspace(min_val, max_val, num_x),\n",
    "        np.linspace(min_val, max_val, num_y),\n",
    "        indexing='xy',\n",
    "    )\n",
    "    coord_grid = np.stack(coord_grid, axis=-1) # num_x x num_y x 2 \n",
    "    coord_grid = coord_grid.reshape(-1, 2)\n",
    "    return coord_grid\n",
    "\n",
    "num_px = 100\n",
    "coord_grid = get_coord_grid(0, 1, num_px, num_px)\n",
    "values = f(coord_grid)\n",
    "\n",
    "plt.imshow(values.reshape(num_px, num_px), cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finite diff\n",
    "\n",
    "dx = (p[2:,:]-p[:-2,:])/2\n",
    "dy = (p[:,2:]-p[:,:-2])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv :\n",
    "nout = (nin+2p-k)/s + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules \n",
    "import cv2 \n",
    "import numpy as np \n",
    "import os \n",
    "import glob \n",
    "\n",
    "\n",
    "# Define the dimensions of checkerboard \n",
    "CHECKERBOARD = (6, 9) \n",
    "\n",
    "\n",
    "# stop the iteration when specified \n",
    "# accuracy, epsilon, is reached or \n",
    "# specified number of iterations are completed. \n",
    "criteria = (cv2.TERM_CRITERIA_EPS +\n",
    "\t\t\tcv2.TERM_CRITERIA_MAX_ITER, 30, 0.001) \n",
    "\n",
    "\n",
    "# Vector for 3D points \n",
    "threedpoints = [] \n",
    "\n",
    "# Vector for 2D points \n",
    "twodpoints = [] \n",
    "\n",
    "\n",
    "# 3D points real world coordinates \n",
    "objectp3d = np.zeros((1, CHECKERBOARD[0] \n",
    "\t\t\t\t\t* CHECKERBOARD[1], \n",
    "\t\t\t\t\t3), np.float32) # 1 not necessary\n",
    "objectp3d[0, :, :2] = np.mgrid[0:CHECKERBOARD[0], \n",
    "\t\t\t\t\t\t\t0:CHECKERBOARD[1]].T.reshape(-1, 2) \n",
    "prev_img_shape = None\n",
    "\n",
    "\n",
    "# Extracting path of individual image stored \n",
    "# in a given directory. Since no path is \n",
    "# specified, it will take current directory \n",
    "# jpg files alone \n",
    "images = glob.glob('*.jpg') \n",
    "\n",
    "for filename in images: \n",
    "\timage = cv2.imread(filename) \n",
    "\tgrayColor = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "\t# Find the chess board corners \n",
    "\t# If desired number of corners are \n",
    "\t# found in the image then ret = true \n",
    "\tret, corners = cv2.findChessboardCorners( \n",
    "\t\t\t\t\tgrayColor, CHECKERBOARD, \n",
    "\t\t\t\t\tcv2.CALIB_CB_ADAPTIVE_THRESH \n",
    "\t\t\t\t\t+ cv2.CALIB_CB_FAST_CHECK +\n",
    "\t\t\t\t\tcv2.CALIB_CB_NORMALIZE_IMAGE) \n",
    "\n",
    "\t# If desired number of corners can be detected then, \n",
    "\t# refine the pixel coordinates and display \n",
    "\t# them on the images of checker board \n",
    "\tif ret == True: \n",
    "\t\tthreedpoints.append(objectp3d) \n",
    "\n",
    "\t\t# Refining pixel coordinates \n",
    "\t\t# for given 2d points. \n",
    "\t\tcorners2 = cv2.cornerSubPix( \n",
    "\t\t\tgrayColor, corners, (11, 11), (-1, -1), criteria)  # not necessary\n",
    "\n",
    "\t\ttwodpoints.append(corners2) \n",
    "\n",
    "\t\t# Draw and display the corners \n",
    "\t\timage = cv2.drawChessboardCorners(image, \n",
    "\t\t\t\t\t\t\t\t\t\tCHECKERBOARD, \n",
    "\t\t\t\t\t\t\t\t\t\tcorners2, ret) \n",
    "\n",
    "\tcv2.imshow('img', image) \n",
    "\tcv2.waitKey(0) \n",
    "\n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "h, w = image.shape[:2] \n",
    "\n",
    "\n",
    "# Perform camera calibration by \n",
    "# passing the value of above found out 3D points (threedpoints) \n",
    "# and its corresponding pixel coordinates of the \n",
    "# detected corners (twodpoints) \n",
    "ret, matrix, distortion, r_vecs, t_vecs = cv2.calibrateCamera( \n",
    "\tthreedpoints, twodpoints, grayColor.shape[::-1], None, None) \n",
    "\n",
    "\n",
    "# Displaying required output \n",
    "print(\" Camera matrix:\") \n",
    "print(matrix) \n",
    "\n",
    "print(\"\\n Distortion coefficient:\") \n",
    "print(distortion) \n",
    "\n",
    "print(\"\\n Rotation Vectors:\") \n",
    "print(r_vecs) \n",
    "\n",
    "print(\"\\n Translation Vectors:\") \n",
    "print(t_vecs) \n",
    "\n",
    "dst = cv2.undistort(img, matrix, distortion, None, matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
